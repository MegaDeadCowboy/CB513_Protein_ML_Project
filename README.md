# CB513 Protein Secondary Structure Prediction
A neural network implementation for predicting protein secondary structures using the CB513 dataset. This project demonstrates practical bioinformatics machine learning with TensorFlow/Keras, featuring both lightweight and advanced model architectures.

## ğŸ§¬ Project Overview
This project implements sequence-to-sequence models to predict protein secondary structures (Helix, Sheet, Coil) from amino acid sequences. Two model architectures are provided: a lightweight version optimized for resource-constrained environments and a high-performance model with advanced deep learning techniques.

## ğŸ“Š Dataset
- **CB513 Dataset**: 511 protein sequences with secondary structure annotations
- **Input**: Amino acid sequences (20 standard + 3 non-standard amino acids)
- **Output**: 3-state secondary structure classification (H/E/C)
- **Sequence lengths**: 20-874 residues (lightweight model filters to â‰¤256 for efficiency)

## ğŸ—ï¸ Model Architectures

### Lightweight Model (`lightmodel.py`)
**Optimized for laptop-friendly training**
- **Embedding Layer**: 32-dimensional amino acid representations
- **LSTM Layer**: 64 units with dropout regularization
- **Dense Layers**: 32 â†’ 3 units with softmax activation
- **Parameters**: 27,683 (108KB)
- **Training Time**: ~20 seconds on modern hardware
- **Q3 Accuracy**: 55.55%

### Advanced Model (`bigmodel.py`)
**High-performance architecture with attention mechanisms**
- **Embedding Layer**: 128-dimensional amino acid representations
- **Bidirectional LSTM Layers**: 256 + 128 units (stacked)
- **Multi-Head Attention**: Captures long-range amino acid dependencies
- **Layer Normalization**: Residual connections for stable training
- **Dense Layers**: 256 â†’ 128 â†’ 3 units with dropout
- **Parameters**: 2,073,731 (7.91MB)
- **Training Time**: ~21 minutes on AMD Ryzen 7
- **Q3 Accuracy**: 64.93%

## ğŸ“ˆ Performance Results

### Model Comparison
| Model | Parameters | Training Time | Q3 Accuracy | Best Use Case |
|-------|------------|---------------|-------------|---------------|
| Lightweight | 27K | 20 seconds | 55.55% | Quick experiments, limited hardware |
| Advanced | 2.07M | 21 minutes | 64.93% | Research-grade predictions, modern hardware |

### Advanced Model Detailed Results
```
Per-class Performance:
- Helix (H): 72% precision, 69% F1-score
- Coil (C):  73% precision, 65% F1-score  
- Sheet (E): 67% recall, 59% F1-score

Overall Q3 Accuracy: 64.93%
```

### Scientific Context
- **Random Baseline**: 33.3% (3-class prediction)
- **Our Lightweight Model**: 55.55% âœ…
- **Our Advanced Model**: 64.93% âœ…
- **State-of-the-art**: 70-80% (with massive computational resources)

**Achievement**: Professional-grade results on consumer hardware! ğŸ†

## ğŸš€ Quick Start

### Prerequisites
```bash
pip install tensorflow numpy pandas scikit-learn matplotlib seaborn
```

### Running the Models
```bash
# Clone the repository
git clone https://github.com/MegaDeadCowboy/CB513_Protein_ML_Project.git
cd CB513_Protein_ML_Project/src

# Run lightweight model (fast, laptop-friendly)
python lightmodel.py

# Run advanced model (high accuracy, requires modern hardware)
python bigmodel.py

# Interactive prediction
python predict.py
```

### Helper Script
```bash
# From project root
./run_analysis.sh
```

## ğŸ“ Project Structure
```
CB513_Protein_ML_Project/
â”œâ”€â”€ README.md                    # This documentation
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ run_analysis.sh             # Helper execution script
â”œâ”€â”€ data/
â”‚   â””â”€â”€ CB513.csv               # Dataset (511 protein sequences)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lightmodel.py           # Lightweight LSTM model
â”‚   â”œâ”€â”€ bigmodel.py             # Advanced model with attention
â”‚   â”œâ”€â”€ predict.py              # Interactive prediction interface
â”‚   â””â”€â”€ CB513_quickview.py      # Data exploration script
â”œâ”€â”€ models/                     # Trained model files
â””â”€â”€ results/                    # Training outputs and analysis
```

## ğŸ”¬ Technical Features

### Advanced Model Innovations
- **Bidirectional LSTM**: Processes sequences in both directions for context
- **Multi-Head Attention**: Captures complex amino acid interaction patterns
- **Residual Connections**: Enables stable training of deeper networks
- **Layer Normalization**: Improves convergence and generalization
- **Class Weight Balancing**: Handles imbalanced secondary structure distribution

### Preprocessing Pipeline
- **Amino acid vocabulary**: Standard 20 + 3 non-standard (Uâ†’C, Xâ†’A, Zâ†’E)
- **Sequence filtering**: Configurable length limits for memory efficiency
- **Class weight computation**: Automatic balancing for protein structure distribution
- **Masking system**: Proper handling of padded positions during training

## ğŸ’» Hardware Requirements

### Lightweight Model
- **RAM**: 4GB minimum
- **CPU**: Any modern processor
- **Training Time**: <1 minute
- **Use Case**: Rapid prototyping, educational purposes

### Advanced Model
- **RAM**: 8GB+ recommended (16GB ideal)
- **CPU**: Multi-core processor (AMD Ryzen 7 / Intel i7+)
- **Training Time**: 15-30 minutes
- **Use Case**: Research, production applications

## ğŸ§ª Interactive Prediction
```bash
# Run interactive prediction system
python src/predict.py

# Example usage:
Enter protein sequence: MKLLVLSLSLVLVAPMAAQTPFQQ
Predicted structure:   CCCCCCCCCCCCCCCCCCCCCCC
```

## ğŸ“Š Biological Relevance

### Secondary Structure Types
- **Helix (H)**: Î±-helical regions - highly structured, easier to predict
- **Sheet (E)**: Î²-sheet regions - structured but more variable
- **Coil (C)**: Random coil regions - unstructured, inherently difficult

### Model Performance Insights
- **Helix Prediction Excellence**: 72% precision demonstrates strong Î±-helix pattern recognition
- **Balanced Performance**: All three structure types predicted above random baseline
- **Attention Benefits**: Multi-head attention captures long-range amino acid dependencies crucial for structure formation

## ğŸ”„ Future Enhancements
- [ ] 8-state secondary structure prediction (vs current 3-state)
- [ ] Convolutional layers for local amino acid pattern recognition
- [ ] Ensemble methods combining multiple model architectures
- [ ] Transfer learning from larger protein structure datasets
- [ ] Web interface for broader accessibility
- [ ] Integration with protein databases (PDB, UniProt)

## ğŸ“„ Citation
If you use this work in your research, please cite:
```
CB513 Protein Secondary Structure Prediction
GitHub: https://github.com/MegaDeadCowboy/CB513_Protein_ML_Project
```

## ğŸ¤ Contributing
Contributions are welcome! Please feel free to submit pull requests or open issues for bugs and feature requests.

## ğŸ“ License
This project is open source and available under the MIT License.

---

**Built with**: TensorFlow, Python